<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>cBrainMRIPrePro.pipe API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>cBrainMRIPrePro.pipe</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import copy
import logging
import os
import re
import shutil
from abc import ABC
from typing import List, Tuple, Dict, Optional, Union

import ants
import numpy as np
import torch
from HD_BET.run import run_hd_bet

from .utils.files import safe_file_name, split_filename, load_nifty_volume_as_array, save_to_nii
from .utils.image_processing import min_max_scaling, invert_min_max_scaling, get_head_mask, zscore_normalize

logger = logging.getLogger(__name__)


class DataPreprocessing(ABC):
    &#34;&#34;&#34;
    Class for data cBrainMRIPrePro input modalities as a dict:
        - Bias field correction of modalities (n4_correction args) (optional)
        - resampling (optional)
        - Co-registration: If template is set to True. Register to reference to template and then register other
                           modalities to reference.
                           If template is set to False. Register to reference
        - Skull-stripped the reference modalities and apply the mask on others modalities
        - Normalization Z-Score (optional)
    Template is the SRI24 LPS atlas (as used in BraTS challenge)
    It will add the suffix of the keys to data of each step. so if your keys is &#34;T2&#34; and values &#34;/path/data_t1.nii.gz&#34;
    it will split the values and look at the last suffix &#34;t1&#34;, so will be data_step_t1_T2.nii.gz
    it will ignore case sensitivity, so if keys is &#34;T1&#34; and values &#34;/path/data_t1.nii.gz&#34;, the step will be
    data_step_t1.nii.gz

    Args:
        dict_image: keys is the corresponding modality and value is path, ie {&#34;T1&#34;: &#34;t1_path&#34;, &#34;T2&#34;: &#34;t2_path&#34;} ..
        reference: reference modality (used for co-registration and ss). if reference is not in dict_image,
                   no cBrainMRIPrePro step is applied, except for coregistration.
        output_folder: output directory were to save cBrainMRIPrePro data
        resample_spacing: resolution for resampling (ie (1, 1, 1) in mm
        inter_type_resample: mode for resample 0 (Linear), 1 (NearestNeighbor), 2 (Gaussian), 3 (WindowedSinc),
                             4 (BSpline), default: 4
        n4_correction: bias field correction. Specified as list corresponding to keys of dict_image
        do_coregistration: set to True to coregister the data
        template: set to true to register the data in template space
        inter_type_apply_transform_registration: choice of interpolator for apply affine transform of registration
        0 (Linear), 1 (NearestNeighbor), 2 (MultiLabel), 3 (Gaussian), 4 (BSpline), 4 (CosineWindowedSinc),
        6 (WelchWindowedSinc), 7 (HammingWindowedSinc), 8 (LanczosWindowedSinc), 9 (GenericLabel) default: 4
        do_ss: use HD-BET to skull-strip the reference and apply mask on other modalities.
               do_coregistration need to be set to True to have a reference
        normalize_z_score: normalize skull-stripped image by substraction the mean of the whole brain
                           (considers non zero) and dividing by the standard deviation
        scaling_factor_z_score: scaling factor to apply to normalization (default: 1)
        device: device to run HD-BT (default GPU: &#34;0&#34;), you can use &#34;cpu&#34;.
        overwrite: if a step file already exist. will overwrite it. (default False)
        save_step: specify the step that you want to save : (&#34;resample&#34;, &#34;n4_correction&#34;, &#34;coregistration&#34;,
                                                            &#34;affine_transform&#34;, &#34;skullstripping&#34;, &#34;normalize&#34;)
                   &#39;resample: save the resampling image&#39;
                   &#39;n4: save bias field correction with already applied previous step&#39;
                   &#39;coregistration: save coregistered image with already applied previous step&#39;
                   &#39;affine: save affine transform of registration&#39;
                   &#39;mask: save brain mask resulting of ss of reference&#39;
                   &#39;ss: save all skull-stripped image&#39;
    &#34;&#34;&#34;

    def __init__(self,
                 dict_image: Dict[str, str],
                 reference: Dict[str, str],
                 output_folder: str,
                 resample_spacing: Optional[Tuple[int, int, int]] = None,
                 inter_type_resample: int = 4,
                 n4_correction: Optional[List] = None,
                 do_coregistration: bool = True,
                 template: bool = True,
                 inter_type_apply_transform_registration: int = 4,
                 do_ss: bool = True,
                 normalize_z_score: Optional[List] = None,
                 scaling_factor_z_score: int = 1,
                 device: str = &#34;0&#34;,
                 overwrite: bool = False,
                 save_step: Union[Tuple[str], List[str]] = (
                         &#34;resample&#34;, &#34;n4_correction&#34;, &#34;coregistration&#34;, &#34;affine_transform&#34;, &#34;skullstripping&#34;,
                         &#34;normalize&#34;),

                 ) -&gt; None:

        self.dict_image = dict_image
        self.reference = reference
        self.output_folder = output_folder
        self.resample_spacing = resample_spacing
        self.inter_type_resample = inter_type_resample
        self.inter_type_apply_transform_registration = inter_type_apply_transform_registration
        self.n4_correction = n4_correction
        self.template = template
        self.do_coregistration = do_coregistration
        self.do_ss = do_ss
        self.normalize_z_score = normalize_z_score
        self.scaling_factor_z_score = scaling_factor_z_score
        self.device = device
        self.overwrite = overwrite
        self.save_step = list(save_step)
        self.default_step = (
            &#34;resample&#34;, &#34;n4_correction&#34;, &#34;coregistration&#34;, &#34;affine_transform&#34;, &#34;skullstripping&#34;, &#34;normalize&#34;)
        self.default_inter_type_apply_transform_registration = {0: &#34;linear&#34;, 1: &#34;nearestNeighbor&#34;, 2: &#34;multiLabel&#34;,
                                                                3: &#34;gaussian&#34;, 4: &#34;bSpline&#34;, 5: &#34;cosineWindowedSinc&#34;,
                                                                6: &#34;welchWindowedSinc&#34;, 7: &#34;hammingWindowedSinc&#34;,
                                                                8: &#34;lanczosWindowedSinc&#34;, 9: &#34;genericLabel&#34;}

        assert len(self.reference) == 1, &#34;Reference must be unique and contains a key representing modality and &#34; \
                                         &#34;a value corresponding to the path&#34;

        if self.resample_spacing:
            assert len(self.resample_spacing) == 3, f&#34;Resample spacing need to contains 3 values,&#34; \
                                                    f&#34; actually {len(self.resample_spacing)}&#34;

        if self.n4_correction:
            assert set(self.n4_correction).issubset(
                self.dict_image.keys()), f&#34;n4_correction {self.n4_correction} must be in &#34; \
                                         f&#34;dict_image {self.dict_image.keys()}&#34;
        if self.normalize_z_score:
            assert set(self.normalize_z_score).issubset(
                self.dict_image.keys()), f&#34;normalize_z_score {self.normalize_z_score} must be in &#34; \
                                         f&#34;dict_image {self.dict_image.keys()}&#34;

        assert self.inter_type_apply_transform_registration in self.default_inter_type_apply_transform_registration, \
            f&#34;inter_type_apply_transform_registration must be comprise between 0 and 9: &#34; \
            f&#34;{self.default_inter_type_apply_transform_registration}&#34;
        self.inter_type_apply_transform_registration = self.default_inter_type_apply_transform_registration[
            self.inter_type_apply_transform_registration]

        if do_ss:
            assert do_coregistration, &#34;if do_ss is set to True, do_coregistration need to be set to true to have a &#34; \
                                      &#34;reference to apply brain mask on possible others modalities in dict_image&#34;

        for saving_step in self.save_step:
            assert saving_step in self.default_step, f&#34;{save_step} must be in {self.default_step}&#34;

        if len(self.save_step) &lt; 1:
            logger.warning(&#34;You don&#39;t save any step&#34;)

        # Check modalities files exist and check for adding a suffix
        for mod, mod_path in self.dict_image.items():
            assert os.path.exists(mod_path), f&#34;{mod} path not exist&#34;
            _, fnm, ext = split_filename(mod_path)

        assert os.path.exists(self.reference[list(self.reference.keys())[0]]), \
            f&#34;{list(self.reference.values())[0]} path not exist&#34;

        if self.template:
            self.template = os.path.join(os.path.dirname(os.path.abspath(utils.__file__)), &#34;Atlas_SRI&#34;,
                                         &#34;spgr_unstrip_lps.nii.gz&#34;)

        self.device = int(device) if torch.cuda.is_available() else &#34;cpu&#34;

    def _create_folders_step(self) -&gt; None:
        # create intermediate folder
        folders_step = []
        folders_step.extend([&#34;resample&#34;]) if self.resample_spacing else folders_step
        folders_step.extend([&#34;n4_correction&#34;]) if self.n4_correction else folders_step
        folders_step.extend([&#34;coregistration&#34;]) if self.do_coregistration else folders_step
        folders_step.extend([&#34;affine_transform&#34;]) if &#34;affine_transform&#34; in self.save_step else folders_step
        folders_step.extend([&#34;skullstripping&#34;]) if self.do_ss else folders_step
        folders_step.extend([&#34;normalize&#34;]) if self.normalize_z_score else folders_step
        for folder in folders_step:
            if not os.path.exists(os.path.join(self.output_folder, folder)):
                os.makedirs(os.path.join(self.output_folder, folder), exist_ok=True)

    @staticmethod
    def check_output_filename(filename: str, modality: str, step: str) -&gt; str:
        &#34;&#34;&#34;
        check output filename. if mod is already in filename will not add it
        :param filename: filename
        :param modality: modality
        :param step: cBrainMRIPrePro step
        :return: filename
        &#34;&#34;&#34;
        if step:
            if modality not in filename:
                filename += f&#34;_{step}_{modality}&#34;
            else:
                fnm = filename.split(modality)
                fnm.extend([step, modality])
                filename = re.sub(&#34;_+&#34;, &#34;_&#34;, safe_file_name(&#34;_&#34;.join(fnm)))

        return filename

    @staticmethod
    def save_image(img: ants.ANTsImage, output_filename: str) -&gt; None:
        ants.image_write(image=img, filename=output_filename)

    def _save_transform(self, img: ants.ANTsTransform, filename: str, modality: str, step: str, save_folder: str,
                        ext: str) -&gt; None:
        filename = self.check_output_filename(filename=filename, modality=modality, step=step)
        output_filename = os.path.join(self.output_folder, save_folder, f&#34;{filename}{ext}&#34;)
        ants.write_transform(transform=img, filename=output_filename)

    def _run_resample_image(self, img_dict: dict) -&gt; None:
        logger.info(&#34;Perform resampling&#34;)
        for mod, mod_path in img_dict.items():
            _, fnm, ext = split_filename(mod_path)
            output_filename = os.path.join(self.output_folder, &#34;resample&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod,
                                                                      step=&#34;resample&#34;) + ext)
            if os.path.exists(output_filename) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename}&#34;)
            img_resample = ants.resample_image(image=ants.image_read(mod_path), resample_params=self.resample_spacing,
                                               interp_type=self.inter_type_resample)
            ants.image_write(image=img_resample, filename=output_filename)

    def _run_bias_field_correction(self, img_dict: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform bias field correction&#34;)
        # N4 includes a log transform, so be aware of negative values
        # will check range of image intensities and rescale to positive if negative values
        # 0) get range of input image = [a,b]
        # 1) rescale input image to be in a positive, e.g., [10 , 1000]
        # 2) perform N4 on 1)
        # 3) rescale image from 2) to be in [a,b]
        # https://github.com/ANTsX/ANTs/issues/822
        for mod_n4 in self.n4_correction:
            _, fnm, ext = split_filename(img_dict[mod_n4])
            output_filename = os.path.join(self.output_folder, &#34;n4_correction&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod_n4,
                                                                      step=&#34;n4&#34;) + ext)
            if os.path.exists(output_filename) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename}&#34;)
            img = ants.image_read(img_dict[mod_n4])
            img_array = img.numpy()
            img_array_scaled, min_, scale_ = min_max_scaling(input_array=img_array, scaling_range=(10, 1000))
            img = img.new_image_like(img_array_scaled)
            # To reproduce behavior as in ANTs a mask equally weighting the entire image is supplied.
            # In ANTsPy when no mask is supplied, a mask is computed with the get_mask function. Function is based
            # on a mean threshold. Resulting head mask is very often filled with holes. Here we compute a real head
            # mask with no holes.
            head_mask = get_head_mask(img_array)
            head_mask = img.new_image_like(head_mask).astype(&#34;float32&#34;)  # pass to float32 to be read by n4 function
            img_n4 = ants.n4_bias_field_correction(image=img, mask=head_mask, verbose=False)  # 2
            img_array_n4 = img_n4.numpy()
            img_array_unscaled = invert_min_max_scaling(input_array_scaled=img_array_n4, scale_=scale_, min_=min_)
            img_n4 = img.new_image_like(img_array_unscaled)  # 3
            ants.image_write(image=img_n4, filename=output_filename)

    def _run_coregistration(self, img_dict: Dict[str, str], reference: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform coregistration&#34;)
        # img_reference = ants.image_read(list(reference.values())[0])
        save_affine_transform = [&#34;fwdtransforms&#34;, &#34;invtransforms&#34;]
        _, fnm_ref, ext_ref = split_filename(list(reference.values())[0])

        step_rf = &#34;register&#34; if list(reference.values())[0] in img_dict else &#34;reference&#34;
        output_filename_ref = os.path.join(self.output_folder, &#34;coregistration&#34;,
                                           self.check_output_filename(filename=fnm_ref,
                                                                      modality=list(reference.keys())[0],
                                                                      step=step_rf) + ext_ref)
        check_affine_transform_ref_save = []
        if &#34;affine_transform&#34; in self.save_step:
            for transform in save_affine_transform:
                check_affine_transform_ref_save.append(
                    os.path.exists(os.path.join(self.output_folder, &#34;affine_transform&#34;,
                                                self.check_output_filename(filename=fnm_ref,
                                                                           modality=list(reference.keys())[0],
                                                                           step=transform) + &#34;.mat&#34;)))

        if not self.overwrite and output_filename_ref and all(check_affine_transform_ref_save):
            logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename_ref}&#34;)
            pass
        else:
            if self.template:
                logger.info(f&#34;Process: {output_filename_ref}&#34;)
                fixed_image = ants.image_read(self.template)
                moving_image = ants.image_read(list(reference.values())[0])
                reg = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform=&#34;Affine&#34;)
                warped_image = ants.apply_transforms(fixed=fixed_image, moving=moving_image,
                                                     transformlist=reg[&#39;fwdtransforms&#39;],
                                                     interpolator=self.inter_type_apply_transform_registration)
                ants.image_write(image=warped_image, filename=output_filename_ref)

                if &#34;affine_transform&#34; in self.save_step:
                    for transform in reg:
                        if transform in save_affine_transform:
                            self._save_transform(img=ants.read_transform(reg[transform][0]), filename=fnm_ref,
                                                 modality=list(reference.keys())[0],
                                                 step=transform, save_folder=&#34;affine_transform&#34;, ext=&#34;.mat&#34;)
            else:
                shutil.copy(src=list(reference.values())[0],
                            dst=os.path.join(self.output_folder, &#34;coregistration&#34;,
                                             self.check_output_filename(filename=fnm_ref,
                                                                        modality=list(reference.keys())[0],
                                                                        step=&#34;reference&#34;) + ext_ref))

        modalities_to_register = copy.deepcopy(img_dict)
        if list(reference.values())[0] in img_dict:
            modalities_to_register.pop(list(reference.keys())[0], None)
        for mod, mod_path in modalities_to_register.items():
            _, fnm, ext = split_filename(mod_path)
            output_filename = os.path.join(self.output_folder, &#34;coregistration&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod,
                                                                      step=&#34;register&#34;) + ext)

            check_affine_transform_save = []
            if &#34;affine_transform&#34; in self.save_step:
                for transform in save_affine_transform:
                    check_affine_transform_save.append(
                        os.path.exists(os.path.join(self.output_folder, &#34;affine_transform&#34;,
                                                    self.check_output_filename(
                                                        filename=fnm,
                                                        modality=mod,
                                                        step=transform) + &#34;.mat&#34;)))

            if os.path.exists(output_filename) and all(check_affine_transform_save) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename_ref}&#34;)
            fixed_image = ants.image_read(output_filename_ref)
            moving_image = ants.image_read(mod_path)
            reg = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform=&#39;Affine&#39;)
            warped_image = ants.apply_transforms(fixed=fixed_image, moving=moving_image,
                                                 transformlist=reg[&#39;fwdtransforms&#39;], interpolator=&#34;bSpline&#34;)
            ants.image_write(image=warped_image, filename=output_filename)

            if &#34;affine_transform&#34; in self.save_step:
                for transform in reg:
                    if transform in save_affine_transform:
                        self._save_transform(img=ants.read_transform(reg[transform][0]), filename=fnm,
                                             modality=mod, step=transform, save_folder=&#34;affine_transform&#34;, ext=&#34;.mat&#34;)

    def _run_skull_stripping(self, img_dict: Dict[str, str], reference: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform Skull Stripping using HD-BET&#34;)
        ref_path = list(reference.values())[0]
        _, fnm_ref, ext_ref = split_filename(ref_path)
        output_fname_ss = os.path.join(self.output_folder, &#34;skullstripping&#34;, fnm_ref + &#34;_ss&#34; + ext_ref)
        # get correct mask name
        filename_mask = self.check_output_filename(filename=fnm_ref,
                                                   modality=list(reference.keys())[0],
                                                   step=&#34;brain_mask&#34;) + ext_ref
        new_filename_mask = os.path.join(self.output_folder, &#34;skullstripping&#34;, filename_mask)
        if os.path.exists(new_filename_mask) and not self.overwrite:
            logger.warning(f&#34;Already exist and not overwrite, So pass ... {new_filename_mask}&#34;)
            pass
        else:
            logger.info(f&#34;Create brain mask&#34;)
            run_hd_bet(mri_fnames=list(reference.values())[0], output_fnames=output_fname_ss,
                       device=self.device)
            os.remove(output_fname_ss)

            os.rename(src=os.path.join(self.output_folder, &#34;skullstripping&#34;, fnm_ref + &#34;_ss&#34; + &#34;_mask&#34; + ext_ref),
                      dst=new_filename_mask)

        mask_array, _ = load_nifty_volume_as_array(input_path_file=new_filename_mask)
        for mod, mod_path in img_dict.items():  # loose some seconds because skull-strip reference again
            _, fnm, ext = split_filename(mod_path)
            filename_mod = self.check_output_filename(filename=fnm, modality=mod, step=&#34;ss&#34;) + ext_ref
            output_filename_mod = os.path.join(self.output_folder, &#34;skullstripping&#34;,
                                               filename_mod + &#34;.nii.gz&#34;)
            if os.path.exists(output_filename_mod) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename_mod}&#34;)

                continue
            logger.info(f&#34;Process: {output_filename_mod}&#34;)
            file_array, file_header = self.apply_brain_mask(input_file_path=mod_path, mask=mask_array)
            save_to_nii(im=file_array, header=file_header,
                        output_dir=os.path.join(self.output_folder, &#34;skullstripping&#34;),
                        filename=filename_mod, mode=&#34;image&#34;, gzip=True)

    def _run_normalize_z_score(self, img_dict: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform z-score normalization&#34;)
        for mod_normalize in self.normalize_z_score:
            _, fnm, ext = split_filename(img_dict[mod_normalize])
            output_filename = os.path.join(self.output_folder, &#34;normalize&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod_normalize,
                                                                      step=&#34;normalize&#34;) + ext)
            if os.path.exists(output_filename) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename}&#34;)
            img = ants.image_read(img_dict[mod_normalize])
            img_array = img.numpy()
            img_array_normalize = zscore_normalize(input_array=img_array, scaling_factor=self.scaling_factor_z_score)
            img = img.new_image_like(img_array_normalize)
            ants.image_write(image=img, filename=output_filename)

    @staticmethod
    def apply_brain_mask(input_file_path: str, mask: Union[str, np.ndarray]) \
            -&gt; Tuple[np.ndarray, Tuple[Tuple, Tuple, Tuple]]:

        mask_array = mask
        if isinstance(mask, str):
            mask_array, _ = load_nifty_volume_as_array(input_path_file=mask)

        file_array, file_header = load_nifty_volume_as_array(input_path_file=input_file_path)

        file_array[mask_array == 0] = 0

        return file_array, file_header

    def run_pipeline(self):

        self._create_folders_step()

        step_dict, reference_dict, step, folder_path = {}, {}, &#34;&#34;, {}

        if self.n4_correction:
            self._run_bias_field_correction(img_dict=self.dict_image)

        if self.resample_spacing:
            step_dict = {k: os.path.join(self.output_folder, &#34;n4_correction&#34;,
                                         self.check_output_filename(filename=split_filename(v)[1],
                                                                    modality=k,
                                                                    step=&#34;n4&#34;) +
                                         split_filename(v)[2]) if k in self.n4_correction else v for k, v in
                         self.dict_image.items()}
            self._run_resample_image(img_dict=step_dict)

        if self.do_coregistration:
            if self.resample_spacing and self.n4_correction:
                step = {k: &#34;n4_resample&#34; if k in self.n4_correction else &#34;resample&#34; for k in self.dict_image}
                folder_path = {
                    k: os.path.join(self.output_folder, &#34;resample&#34;) for k in self.dict_image}
            elif self.resample_spacing:
                step = {k: &#34;resample&#34; for k in self.dict_image}
                folder_path = {k: os.path.join(self.output_folder, &#34;resample&#34;) for k in self.dict_image}
            elif self.n4_correction:
                step = {k: &#34;n4&#34; if k in self.n4_correction else &#34;&#34; for k in self.dict_image}
                folder_path = {k: os.path.join(self.output_folder,
                                               &#34;n4_correction&#34;) if k in self.n4_correction else os.path.dirname(v) for
                               k, v in self.dict_image.items()}
            step_dict = {k: os.path.join(folder_path[k],
                                         self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                    step=step[k]) +
                                         split_filename(v)[2]) for k, v in self.dict_image.items()} if \
                (self.resample_spacing or self.n4_correction) else copy.deepcopy(self.dict_image)
            reference_dict = {list(self.reference.keys())[0]: step_dict[list(self.reference.keys())[0]]} if \
                list(self.reference.values())[0] in self.dict_image.values() else copy.deepcopy(self.reference)
            self._run_coregistration(img_dict=step_dict, reference=reference_dict)

        if self.do_ss:
            step_dict = {k: os.path.join(self.output_folder, &#34;coregistration&#34;,
                                         self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                    step=&#34;register&#34;) +
                                         split_filename(v)[2]) for k, v in step_dict.items()}
            reference_dict = {
                k: os.path.join(self.output_folder, &#34;coregistration&#34;,
                                self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                           step=&#34;register&#34;) +
                                split_filename(v)[2]) for k, v in reference_dict.items()}

            self._run_skull_stripping(img_dict=step_dict, reference=reference_dict)

        if self.normalize_z_score:
            step_dict = {k: os.path.join(self.output_folder, &#34;skullstripping&#34;,
                                         self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                    step=&#34;ss&#34;) +
                                         split_filename(v)[2]) for k, v in step_dict.items()}
            self._run_normalize_z_score(img_dict=step_dict)

        # if step to remove
        remove_step = set(self.save_step).symmetric_difference(set(self.default_step))
        if remove_step:
            for step_to_remove in remove_step:
                shutil.rmtree(path=os.path.join(self.output_folder, step_to_remove), ignore_errors=True)


if __name__ == &#34;__main__&#34;:
    import time

    start = time.time()
    preprocess = DataPreprocessing(
        dict_image={&#34;t1&#34;: &#34;t1.nii.gz&#34;,
                    &#34;t1ce&#34;: &#34;t1ce.nii.gz&#34;,
                    &#34;flair&#34;: &#34;flair.nii.gz&#34;,
                    &#34;ct&#34;: &#34;ct.nii.gz&#34;},
        reference={&#34;t1&#34;: &#34;t1.nii.gz&#34;},
        output_folder=&#34;/output_test&#34;,
        resample_spacing=None,
        n4_correction=[&#34;t1&#34;, &#34;t1ce&#34;, &#34;flair&#34;],
        inter_type_resample=4,
        inter_type_apply_transform_registration=4,
        template=True,
        do_coregistration=True,
        do_ss=True,
        normalize_z_score=[&#34;t1&#34;, &#34;t1ce&#34;, &#34;flair&#34;],
        device=&#34;0&#34;, overwrite=True,
    )
    preprocess.run_pipeline()
    print(f&#34;total run time is {start - time.time()}&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="cBrainMRIPrePro.pipe.DataPreprocessing"><code class="flex name class">
<span>class <span class="ident">DataPreprocessing</span></span>
<span>(</span><span>dict_image: Dict[str, str], reference: Dict[str, str], output_folder: str, resample_spacing: Union[Tuple[int, int, int], NoneType] = None, inter_type_resample: int = 4, n4_correction: Union[List, NoneType] = None, do_coregistration: bool = True, template: bool = True, inter_type_apply_transform_registration: int = 4, do_ss: bool = True, normalize_z_score: Union[List, NoneType] = None, scaling_factor_z_score: int = 1, device: str = '0', overwrite: bool = False, save_step: Union[Tuple[str], List[str]] = ('resample', 'n4_correction', 'coregistration', 'affine_transform', 'skullstripping', 'normalize'))</span>
</code></dt>
<dd>
<div class="desc"><p>Class for data cBrainMRIPrePro input modalities as a dict:
- Bias field correction of modalities (n4_correction args) (optional)
- resampling (optional)
- Co-registration: If template is set to True. Register to reference to template and then register other
modalities to reference.
If template is set to False. Register to reference
- Skull-stripped the reference modalities and apply the mask on others modalities
- Normalization Z-Score (optional)
Template is the SRI24 LPS atlas (as used in BraTS challenge)
It will add the suffix of the keys to data of each step. so if your keys is "T2" and values "/path/data_t1.nii.gz"
it will split the values and look at the last suffix "t1", so will be data_step_t1_T2.nii.gz
it will ignore case sensitivity, so if keys is "T1" and values "/path/data_t1.nii.gz", the step will be
data_step_t1.nii.gz</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dict_image</code></strong></dt>
<dd>keys is the corresponding modality and value is path, ie {"T1": "t1_path", "T2": "t2_path"} ..</dd>
<dt><strong><code>reference</code></strong></dt>
<dd>reference modality (used for co-registration and ss). if reference is not in dict_image,
no cBrainMRIPrePro step is applied, except for coregistration.</dd>
<dt><strong><code>output_folder</code></strong></dt>
<dd>output directory were to save cBrainMRIPrePro data</dd>
<dt><strong><code>resample_spacing</code></strong></dt>
<dd>resolution for resampling (ie (1, 1, 1) in mm</dd>
<dt><strong><code>inter_type_resample</code></strong></dt>
<dd>mode for resample 0 (Linear), 1 (NearestNeighbor), 2 (Gaussian), 3 (WindowedSinc),
4 (BSpline), default: 4</dd>
<dt><strong><code>n4_correction</code></strong></dt>
<dd>bias field correction. Specified as list corresponding to keys of dict_image</dd>
<dt><strong><code>do_coregistration</code></strong></dt>
<dd>set to True to coregister the data</dd>
<dt><strong><code>template</code></strong></dt>
<dd>set to true to register the data in template space</dd>
<dt><strong><code>inter_type_apply_transform_registration</code></strong></dt>
<dd>choice of interpolator for apply affine transform of registration</dd>
<dt>0 (Linear), 1 (NearestNeighbor), 2 (MultiLabel), 3 (Gaussian), 4 (BSpline), 4 (CosineWindowedSinc),</dt>
<dt>6 (WelchWindowedSinc), 7 (HammingWindowedSinc), 8 (LanczosWindowedSinc), 9 (GenericLabel) default: 4</dt>
<dt><strong><code>do_ss</code></strong></dt>
<dd>use HD-BET to skull-strip the reference and apply mask on other modalities.
do_coregistration need to be set to True to have a reference</dd>
<dt><strong><code>normalize_z_score</code></strong></dt>
<dd>normalize skull-stripped image by substraction the mean of the whole brain
(considers non zero) and dividing by the standard deviation</dd>
<dt><strong><code>scaling_factor_z_score</code></strong></dt>
<dd>scaling factor to apply to normalization (default: 1)</dd>
<dt><strong><code>device</code></strong></dt>
<dd>device to run HD-BT (default GPU: "0"), you can use "cpu".</dd>
<dt><strong><code>overwrite</code></strong></dt>
<dd>if a step file already exist. will overwrite it. (default False)</dd>
<dt><strong><code>save_step</code></strong></dt>
<dd>specify the step that you want to save : ("resample", "n4_correction", "coregistration",
"affine_transform", "skullstripping", "normalize")
'resample: save the resampling image'
'n4: save bias field correction with already applied previous step'
'coregistration: save coregistered image with already applied previous step'
'affine: save affine transform of registration'
'mask: save brain mask resulting of ss of reference'
'ss: save all skull-stripped image'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataPreprocessing(ABC):
    &#34;&#34;&#34;
    Class for data cBrainMRIPrePro input modalities as a dict:
        - Bias field correction of modalities (n4_correction args) (optional)
        - resampling (optional)
        - Co-registration: If template is set to True. Register to reference to template and then register other
                           modalities to reference.
                           If template is set to False. Register to reference
        - Skull-stripped the reference modalities and apply the mask on others modalities
        - Normalization Z-Score (optional)
    Template is the SRI24 LPS atlas (as used in BraTS challenge)
    It will add the suffix of the keys to data of each step. so if your keys is &#34;T2&#34; and values &#34;/path/data_t1.nii.gz&#34;
    it will split the values and look at the last suffix &#34;t1&#34;, so will be data_step_t1_T2.nii.gz
    it will ignore case sensitivity, so if keys is &#34;T1&#34; and values &#34;/path/data_t1.nii.gz&#34;, the step will be
    data_step_t1.nii.gz

    Args:
        dict_image: keys is the corresponding modality and value is path, ie {&#34;T1&#34;: &#34;t1_path&#34;, &#34;T2&#34;: &#34;t2_path&#34;} ..
        reference: reference modality (used for co-registration and ss). if reference is not in dict_image,
                   no cBrainMRIPrePro step is applied, except for coregistration.
        output_folder: output directory were to save cBrainMRIPrePro data
        resample_spacing: resolution for resampling (ie (1, 1, 1) in mm
        inter_type_resample: mode for resample 0 (Linear), 1 (NearestNeighbor), 2 (Gaussian), 3 (WindowedSinc),
                             4 (BSpline), default: 4
        n4_correction: bias field correction. Specified as list corresponding to keys of dict_image
        do_coregistration: set to True to coregister the data
        template: set to true to register the data in template space
        inter_type_apply_transform_registration: choice of interpolator for apply affine transform of registration
        0 (Linear), 1 (NearestNeighbor), 2 (MultiLabel), 3 (Gaussian), 4 (BSpline), 4 (CosineWindowedSinc),
        6 (WelchWindowedSinc), 7 (HammingWindowedSinc), 8 (LanczosWindowedSinc), 9 (GenericLabel) default: 4
        do_ss: use HD-BET to skull-strip the reference and apply mask on other modalities.
               do_coregistration need to be set to True to have a reference
        normalize_z_score: normalize skull-stripped image by substraction the mean of the whole brain
                           (considers non zero) and dividing by the standard deviation
        scaling_factor_z_score: scaling factor to apply to normalization (default: 1)
        device: device to run HD-BT (default GPU: &#34;0&#34;), you can use &#34;cpu&#34;.
        overwrite: if a step file already exist. will overwrite it. (default False)
        save_step: specify the step that you want to save : (&#34;resample&#34;, &#34;n4_correction&#34;, &#34;coregistration&#34;,
                                                            &#34;affine_transform&#34;, &#34;skullstripping&#34;, &#34;normalize&#34;)
                   &#39;resample: save the resampling image&#39;
                   &#39;n4: save bias field correction with already applied previous step&#39;
                   &#39;coregistration: save coregistered image with already applied previous step&#39;
                   &#39;affine: save affine transform of registration&#39;
                   &#39;mask: save brain mask resulting of ss of reference&#39;
                   &#39;ss: save all skull-stripped image&#39;
    &#34;&#34;&#34;

    def __init__(self,
                 dict_image: Dict[str, str],
                 reference: Dict[str, str],
                 output_folder: str,
                 resample_spacing: Optional[Tuple[int, int, int]] = None,
                 inter_type_resample: int = 4,
                 n4_correction: Optional[List] = None,
                 do_coregistration: bool = True,
                 template: bool = True,
                 inter_type_apply_transform_registration: int = 4,
                 do_ss: bool = True,
                 normalize_z_score: Optional[List] = None,
                 scaling_factor_z_score: int = 1,
                 device: str = &#34;0&#34;,
                 overwrite: bool = False,
                 save_step: Union[Tuple[str], List[str]] = (
                         &#34;resample&#34;, &#34;n4_correction&#34;, &#34;coregistration&#34;, &#34;affine_transform&#34;, &#34;skullstripping&#34;,
                         &#34;normalize&#34;),

                 ) -&gt; None:

        self.dict_image = dict_image
        self.reference = reference
        self.output_folder = output_folder
        self.resample_spacing = resample_spacing
        self.inter_type_resample = inter_type_resample
        self.inter_type_apply_transform_registration = inter_type_apply_transform_registration
        self.n4_correction = n4_correction
        self.template = template
        self.do_coregistration = do_coregistration
        self.do_ss = do_ss
        self.normalize_z_score = normalize_z_score
        self.scaling_factor_z_score = scaling_factor_z_score
        self.device = device
        self.overwrite = overwrite
        self.save_step = list(save_step)
        self.default_step = (
            &#34;resample&#34;, &#34;n4_correction&#34;, &#34;coregistration&#34;, &#34;affine_transform&#34;, &#34;skullstripping&#34;, &#34;normalize&#34;)
        self.default_inter_type_apply_transform_registration = {0: &#34;linear&#34;, 1: &#34;nearestNeighbor&#34;, 2: &#34;multiLabel&#34;,
                                                                3: &#34;gaussian&#34;, 4: &#34;bSpline&#34;, 5: &#34;cosineWindowedSinc&#34;,
                                                                6: &#34;welchWindowedSinc&#34;, 7: &#34;hammingWindowedSinc&#34;,
                                                                8: &#34;lanczosWindowedSinc&#34;, 9: &#34;genericLabel&#34;}

        assert len(self.reference) == 1, &#34;Reference must be unique and contains a key representing modality and &#34; \
                                         &#34;a value corresponding to the path&#34;

        if self.resample_spacing:
            assert len(self.resample_spacing) == 3, f&#34;Resample spacing need to contains 3 values,&#34; \
                                                    f&#34; actually {len(self.resample_spacing)}&#34;

        if self.n4_correction:
            assert set(self.n4_correction).issubset(
                self.dict_image.keys()), f&#34;n4_correction {self.n4_correction} must be in &#34; \
                                         f&#34;dict_image {self.dict_image.keys()}&#34;
        if self.normalize_z_score:
            assert set(self.normalize_z_score).issubset(
                self.dict_image.keys()), f&#34;normalize_z_score {self.normalize_z_score} must be in &#34; \
                                         f&#34;dict_image {self.dict_image.keys()}&#34;

        assert self.inter_type_apply_transform_registration in self.default_inter_type_apply_transform_registration, \
            f&#34;inter_type_apply_transform_registration must be comprise between 0 and 9: &#34; \
            f&#34;{self.default_inter_type_apply_transform_registration}&#34;
        self.inter_type_apply_transform_registration = self.default_inter_type_apply_transform_registration[
            self.inter_type_apply_transform_registration]

        if do_ss:
            assert do_coregistration, &#34;if do_ss is set to True, do_coregistration need to be set to true to have a &#34; \
                                      &#34;reference to apply brain mask on possible others modalities in dict_image&#34;

        for saving_step in self.save_step:
            assert saving_step in self.default_step, f&#34;{save_step} must be in {self.default_step}&#34;

        if len(self.save_step) &lt; 1:
            logger.warning(&#34;You don&#39;t save any step&#34;)

        # Check modalities files exist and check for adding a suffix
        for mod, mod_path in self.dict_image.items():
            assert os.path.exists(mod_path), f&#34;{mod} path not exist&#34;
            _, fnm, ext = split_filename(mod_path)

        assert os.path.exists(self.reference[list(self.reference.keys())[0]]), \
            f&#34;{list(self.reference.values())[0]} path not exist&#34;

        if self.template:
            self.template = os.path.join(os.path.dirname(os.path.abspath(utils.__file__)), &#34;Atlas_SRI&#34;,
                                         &#34;spgr_unstrip_lps.nii.gz&#34;)

        self.device = int(device) if torch.cuda.is_available() else &#34;cpu&#34;

    def _create_folders_step(self) -&gt; None:
        # create intermediate folder
        folders_step = []
        folders_step.extend([&#34;resample&#34;]) if self.resample_spacing else folders_step
        folders_step.extend([&#34;n4_correction&#34;]) if self.n4_correction else folders_step
        folders_step.extend([&#34;coregistration&#34;]) if self.do_coregistration else folders_step
        folders_step.extend([&#34;affine_transform&#34;]) if &#34;affine_transform&#34; in self.save_step else folders_step
        folders_step.extend([&#34;skullstripping&#34;]) if self.do_ss else folders_step
        folders_step.extend([&#34;normalize&#34;]) if self.normalize_z_score else folders_step
        for folder in folders_step:
            if not os.path.exists(os.path.join(self.output_folder, folder)):
                os.makedirs(os.path.join(self.output_folder, folder), exist_ok=True)

    @staticmethod
    def check_output_filename(filename: str, modality: str, step: str) -&gt; str:
        &#34;&#34;&#34;
        check output filename. if mod is already in filename will not add it
        :param filename: filename
        :param modality: modality
        :param step: cBrainMRIPrePro step
        :return: filename
        &#34;&#34;&#34;
        if step:
            if modality not in filename:
                filename += f&#34;_{step}_{modality}&#34;
            else:
                fnm = filename.split(modality)
                fnm.extend([step, modality])
                filename = re.sub(&#34;_+&#34;, &#34;_&#34;, safe_file_name(&#34;_&#34;.join(fnm)))

        return filename

    @staticmethod
    def save_image(img: ants.ANTsImage, output_filename: str) -&gt; None:
        ants.image_write(image=img, filename=output_filename)

    def _save_transform(self, img: ants.ANTsTransform, filename: str, modality: str, step: str, save_folder: str,
                        ext: str) -&gt; None:
        filename = self.check_output_filename(filename=filename, modality=modality, step=step)
        output_filename = os.path.join(self.output_folder, save_folder, f&#34;{filename}{ext}&#34;)
        ants.write_transform(transform=img, filename=output_filename)

    def _run_resample_image(self, img_dict: dict) -&gt; None:
        logger.info(&#34;Perform resampling&#34;)
        for mod, mod_path in img_dict.items():
            _, fnm, ext = split_filename(mod_path)
            output_filename = os.path.join(self.output_folder, &#34;resample&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod,
                                                                      step=&#34;resample&#34;) + ext)
            if os.path.exists(output_filename) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename}&#34;)
            img_resample = ants.resample_image(image=ants.image_read(mod_path), resample_params=self.resample_spacing,
                                               interp_type=self.inter_type_resample)
            ants.image_write(image=img_resample, filename=output_filename)

    def _run_bias_field_correction(self, img_dict: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform bias field correction&#34;)
        # N4 includes a log transform, so be aware of negative values
        # will check range of image intensities and rescale to positive if negative values
        # 0) get range of input image = [a,b]
        # 1) rescale input image to be in a positive, e.g., [10 , 1000]
        # 2) perform N4 on 1)
        # 3) rescale image from 2) to be in [a,b]
        # https://github.com/ANTsX/ANTs/issues/822
        for mod_n4 in self.n4_correction:
            _, fnm, ext = split_filename(img_dict[mod_n4])
            output_filename = os.path.join(self.output_folder, &#34;n4_correction&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod_n4,
                                                                      step=&#34;n4&#34;) + ext)
            if os.path.exists(output_filename) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename}&#34;)
            img = ants.image_read(img_dict[mod_n4])
            img_array = img.numpy()
            img_array_scaled, min_, scale_ = min_max_scaling(input_array=img_array, scaling_range=(10, 1000))
            img = img.new_image_like(img_array_scaled)
            # To reproduce behavior as in ANTs a mask equally weighting the entire image is supplied.
            # In ANTsPy when no mask is supplied, a mask is computed with the get_mask function. Function is based
            # on a mean threshold. Resulting head mask is very often filled with holes. Here we compute a real head
            # mask with no holes.
            head_mask = get_head_mask(img_array)
            head_mask = img.new_image_like(head_mask).astype(&#34;float32&#34;)  # pass to float32 to be read by n4 function
            img_n4 = ants.n4_bias_field_correction(image=img, mask=head_mask, verbose=False)  # 2
            img_array_n4 = img_n4.numpy()
            img_array_unscaled = invert_min_max_scaling(input_array_scaled=img_array_n4, scale_=scale_, min_=min_)
            img_n4 = img.new_image_like(img_array_unscaled)  # 3
            ants.image_write(image=img_n4, filename=output_filename)

    def _run_coregistration(self, img_dict: Dict[str, str], reference: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform coregistration&#34;)
        # img_reference = ants.image_read(list(reference.values())[0])
        save_affine_transform = [&#34;fwdtransforms&#34;, &#34;invtransforms&#34;]
        _, fnm_ref, ext_ref = split_filename(list(reference.values())[0])

        step_rf = &#34;register&#34; if list(reference.values())[0] in img_dict else &#34;reference&#34;
        output_filename_ref = os.path.join(self.output_folder, &#34;coregistration&#34;,
                                           self.check_output_filename(filename=fnm_ref,
                                                                      modality=list(reference.keys())[0],
                                                                      step=step_rf) + ext_ref)
        check_affine_transform_ref_save = []
        if &#34;affine_transform&#34; in self.save_step:
            for transform in save_affine_transform:
                check_affine_transform_ref_save.append(
                    os.path.exists(os.path.join(self.output_folder, &#34;affine_transform&#34;,
                                                self.check_output_filename(filename=fnm_ref,
                                                                           modality=list(reference.keys())[0],
                                                                           step=transform) + &#34;.mat&#34;)))

        if not self.overwrite and output_filename_ref and all(check_affine_transform_ref_save):
            logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename_ref}&#34;)
            pass
        else:
            if self.template:
                logger.info(f&#34;Process: {output_filename_ref}&#34;)
                fixed_image = ants.image_read(self.template)
                moving_image = ants.image_read(list(reference.values())[0])
                reg = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform=&#34;Affine&#34;)
                warped_image = ants.apply_transforms(fixed=fixed_image, moving=moving_image,
                                                     transformlist=reg[&#39;fwdtransforms&#39;],
                                                     interpolator=self.inter_type_apply_transform_registration)
                ants.image_write(image=warped_image, filename=output_filename_ref)

                if &#34;affine_transform&#34; in self.save_step:
                    for transform in reg:
                        if transform in save_affine_transform:
                            self._save_transform(img=ants.read_transform(reg[transform][0]), filename=fnm_ref,
                                                 modality=list(reference.keys())[0],
                                                 step=transform, save_folder=&#34;affine_transform&#34;, ext=&#34;.mat&#34;)
            else:
                shutil.copy(src=list(reference.values())[0],
                            dst=os.path.join(self.output_folder, &#34;coregistration&#34;,
                                             self.check_output_filename(filename=fnm_ref,
                                                                        modality=list(reference.keys())[0],
                                                                        step=&#34;reference&#34;) + ext_ref))

        modalities_to_register = copy.deepcopy(img_dict)
        if list(reference.values())[0] in img_dict:
            modalities_to_register.pop(list(reference.keys())[0], None)
        for mod, mod_path in modalities_to_register.items():
            _, fnm, ext = split_filename(mod_path)
            output_filename = os.path.join(self.output_folder, &#34;coregistration&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod,
                                                                      step=&#34;register&#34;) + ext)

            check_affine_transform_save = []
            if &#34;affine_transform&#34; in self.save_step:
                for transform in save_affine_transform:
                    check_affine_transform_save.append(
                        os.path.exists(os.path.join(self.output_folder, &#34;affine_transform&#34;,
                                                    self.check_output_filename(
                                                        filename=fnm,
                                                        modality=mod,
                                                        step=transform) + &#34;.mat&#34;)))

            if os.path.exists(output_filename) and all(check_affine_transform_save) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename_ref}&#34;)
            fixed_image = ants.image_read(output_filename_ref)
            moving_image = ants.image_read(mod_path)
            reg = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform=&#39;Affine&#39;)
            warped_image = ants.apply_transforms(fixed=fixed_image, moving=moving_image,
                                                 transformlist=reg[&#39;fwdtransforms&#39;], interpolator=&#34;bSpline&#34;)
            ants.image_write(image=warped_image, filename=output_filename)

            if &#34;affine_transform&#34; in self.save_step:
                for transform in reg:
                    if transform in save_affine_transform:
                        self._save_transform(img=ants.read_transform(reg[transform][0]), filename=fnm,
                                             modality=mod, step=transform, save_folder=&#34;affine_transform&#34;, ext=&#34;.mat&#34;)

    def _run_skull_stripping(self, img_dict: Dict[str, str], reference: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform Skull Stripping using HD-BET&#34;)
        ref_path = list(reference.values())[0]
        _, fnm_ref, ext_ref = split_filename(ref_path)
        output_fname_ss = os.path.join(self.output_folder, &#34;skullstripping&#34;, fnm_ref + &#34;_ss&#34; + ext_ref)
        # get correct mask name
        filename_mask = self.check_output_filename(filename=fnm_ref,
                                                   modality=list(reference.keys())[0],
                                                   step=&#34;brain_mask&#34;) + ext_ref
        new_filename_mask = os.path.join(self.output_folder, &#34;skullstripping&#34;, filename_mask)
        if os.path.exists(new_filename_mask) and not self.overwrite:
            logger.warning(f&#34;Already exist and not overwrite, So pass ... {new_filename_mask}&#34;)
            pass
        else:
            logger.info(f&#34;Create brain mask&#34;)
            run_hd_bet(mri_fnames=list(reference.values())[0], output_fnames=output_fname_ss,
                       device=self.device)
            os.remove(output_fname_ss)

            os.rename(src=os.path.join(self.output_folder, &#34;skullstripping&#34;, fnm_ref + &#34;_ss&#34; + &#34;_mask&#34; + ext_ref),
                      dst=new_filename_mask)

        mask_array, _ = load_nifty_volume_as_array(input_path_file=new_filename_mask)
        for mod, mod_path in img_dict.items():  # loose some seconds because skull-strip reference again
            _, fnm, ext = split_filename(mod_path)
            filename_mod = self.check_output_filename(filename=fnm, modality=mod, step=&#34;ss&#34;) + ext_ref
            output_filename_mod = os.path.join(self.output_folder, &#34;skullstripping&#34;,
                                               filename_mod + &#34;.nii.gz&#34;)
            if os.path.exists(output_filename_mod) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename_mod}&#34;)

                continue
            logger.info(f&#34;Process: {output_filename_mod}&#34;)
            file_array, file_header = self.apply_brain_mask(input_file_path=mod_path, mask=mask_array)
            save_to_nii(im=file_array, header=file_header,
                        output_dir=os.path.join(self.output_folder, &#34;skullstripping&#34;),
                        filename=filename_mod, mode=&#34;image&#34;, gzip=True)

    def _run_normalize_z_score(self, img_dict: Dict[str, str]) -&gt; None:
        logger.info(&#34;Perform z-score normalization&#34;)
        for mod_normalize in self.normalize_z_score:
            _, fnm, ext = split_filename(img_dict[mod_normalize])
            output_filename = os.path.join(self.output_folder, &#34;normalize&#34;,
                                           self.check_output_filename(filename=fnm,
                                                                      modality=mod_normalize,
                                                                      step=&#34;normalize&#34;) + ext)
            if os.path.exists(output_filename) and not self.overwrite:
                logger.warning(f&#34;Already exist and not overwrite, So pass ... {output_filename}&#34;)
                continue
            logger.info(f&#34;Process: {output_filename}&#34;)
            img = ants.image_read(img_dict[mod_normalize])
            img_array = img.numpy()
            img_array_normalize = zscore_normalize(input_array=img_array, scaling_factor=self.scaling_factor_z_score)
            img = img.new_image_like(img_array_normalize)
            ants.image_write(image=img, filename=output_filename)

    @staticmethod
    def apply_brain_mask(input_file_path: str, mask: Union[str, np.ndarray]) \
            -&gt; Tuple[np.ndarray, Tuple[Tuple, Tuple, Tuple]]:

        mask_array = mask
        if isinstance(mask, str):
            mask_array, _ = load_nifty_volume_as_array(input_path_file=mask)

        file_array, file_header = load_nifty_volume_as_array(input_path_file=input_file_path)

        file_array[mask_array == 0] = 0

        return file_array, file_header

    def run_pipeline(self):

        self._create_folders_step()

        step_dict, reference_dict, step, folder_path = {}, {}, &#34;&#34;, {}

        if self.n4_correction:
            self._run_bias_field_correction(img_dict=self.dict_image)

        if self.resample_spacing:
            step_dict = {k: os.path.join(self.output_folder, &#34;n4_correction&#34;,
                                         self.check_output_filename(filename=split_filename(v)[1],
                                                                    modality=k,
                                                                    step=&#34;n4&#34;) +
                                         split_filename(v)[2]) if k in self.n4_correction else v for k, v in
                         self.dict_image.items()}
            self._run_resample_image(img_dict=step_dict)

        if self.do_coregistration:
            if self.resample_spacing and self.n4_correction:
                step = {k: &#34;n4_resample&#34; if k in self.n4_correction else &#34;resample&#34; for k in self.dict_image}
                folder_path = {
                    k: os.path.join(self.output_folder, &#34;resample&#34;) for k in self.dict_image}
            elif self.resample_spacing:
                step = {k: &#34;resample&#34; for k in self.dict_image}
                folder_path = {k: os.path.join(self.output_folder, &#34;resample&#34;) for k in self.dict_image}
            elif self.n4_correction:
                step = {k: &#34;n4&#34; if k in self.n4_correction else &#34;&#34; for k in self.dict_image}
                folder_path = {k: os.path.join(self.output_folder,
                                               &#34;n4_correction&#34;) if k in self.n4_correction else os.path.dirname(v) for
                               k, v in self.dict_image.items()}
            step_dict = {k: os.path.join(folder_path[k],
                                         self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                    step=step[k]) +
                                         split_filename(v)[2]) for k, v in self.dict_image.items()} if \
                (self.resample_spacing or self.n4_correction) else copy.deepcopy(self.dict_image)
            reference_dict = {list(self.reference.keys())[0]: step_dict[list(self.reference.keys())[0]]} if \
                list(self.reference.values())[0] in self.dict_image.values() else copy.deepcopy(self.reference)
            self._run_coregistration(img_dict=step_dict, reference=reference_dict)

        if self.do_ss:
            step_dict = {k: os.path.join(self.output_folder, &#34;coregistration&#34;,
                                         self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                    step=&#34;register&#34;) +
                                         split_filename(v)[2]) for k, v in step_dict.items()}
            reference_dict = {
                k: os.path.join(self.output_folder, &#34;coregistration&#34;,
                                self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                           step=&#34;register&#34;) +
                                split_filename(v)[2]) for k, v in reference_dict.items()}

            self._run_skull_stripping(img_dict=step_dict, reference=reference_dict)

        if self.normalize_z_score:
            step_dict = {k: os.path.join(self.output_folder, &#34;skullstripping&#34;,
                                         self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                    step=&#34;ss&#34;) +
                                         split_filename(v)[2]) for k, v in step_dict.items()}
            self._run_normalize_z_score(img_dict=step_dict)

        # if step to remove
        remove_step = set(self.save_step).symmetric_difference(set(self.default_step))
        if remove_step:
            for step_to_remove in remove_step:
                shutil.rmtree(path=os.path.join(self.output_folder, step_to_remove), ignore_errors=True)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="cBrainMRIPrePro.pipe.DataPreprocessing.apply_brain_mask"><code class="name flex">
<span>def <span class="ident">apply_brain_mask</span></span>(<span>input_file_path: str, mask: Union[str, numpy.ndarray]) ‑> Tuple[numpy.ndarray, Tuple[Tuple, Tuple, Tuple]]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def apply_brain_mask(input_file_path: str, mask: Union[str, np.ndarray]) \
        -&gt; Tuple[np.ndarray, Tuple[Tuple, Tuple, Tuple]]:

    mask_array = mask
    if isinstance(mask, str):
        mask_array, _ = load_nifty_volume_as_array(input_path_file=mask)

    file_array, file_header = load_nifty_volume_as_array(input_path_file=input_file_path)

    file_array[mask_array == 0] = 0

    return file_array, file_header</code></pre>
</details>
</dd>
<dt id="cBrainMRIPrePro.pipe.DataPreprocessing.check_output_filename"><code class="name flex">
<span>def <span class="ident">check_output_filename</span></span>(<span>filename: str, modality: str, step: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>check output filename. if mod is already in filename will not add it
:param filename: filename
:param modality: modality
:param step: cBrainMRIPrePro step
:return: filename</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def check_output_filename(filename: str, modality: str, step: str) -&gt; str:
    &#34;&#34;&#34;
    check output filename. if mod is already in filename will not add it
    :param filename: filename
    :param modality: modality
    :param step: cBrainMRIPrePro step
    :return: filename
    &#34;&#34;&#34;
    if step:
        if modality not in filename:
            filename += f&#34;_{step}_{modality}&#34;
        else:
            fnm = filename.split(modality)
            fnm.extend([step, modality])
            filename = re.sub(&#34;_+&#34;, &#34;_&#34;, safe_file_name(&#34;_&#34;.join(fnm)))

    return filename</code></pre>
</details>
</dd>
<dt id="cBrainMRIPrePro.pipe.DataPreprocessing.save_image"><code class="name flex">
<span>def <span class="ident">save_image</span></span>(<span>img: ants.core.ants_image.ANTsImage, output_filename: str) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def save_image(img: ants.ANTsImage, output_filename: str) -&gt; None:
    ants.image_write(image=img, filename=output_filename)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="cBrainMRIPrePro.pipe.DataPreprocessing.run_pipeline"><code class="name flex">
<span>def <span class="ident">run_pipeline</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_pipeline(self):

    self._create_folders_step()

    step_dict, reference_dict, step, folder_path = {}, {}, &#34;&#34;, {}

    if self.n4_correction:
        self._run_bias_field_correction(img_dict=self.dict_image)

    if self.resample_spacing:
        step_dict = {k: os.path.join(self.output_folder, &#34;n4_correction&#34;,
                                     self.check_output_filename(filename=split_filename(v)[1],
                                                                modality=k,
                                                                step=&#34;n4&#34;) +
                                     split_filename(v)[2]) if k in self.n4_correction else v for k, v in
                     self.dict_image.items()}
        self._run_resample_image(img_dict=step_dict)

    if self.do_coregistration:
        if self.resample_spacing and self.n4_correction:
            step = {k: &#34;n4_resample&#34; if k in self.n4_correction else &#34;resample&#34; for k in self.dict_image}
            folder_path = {
                k: os.path.join(self.output_folder, &#34;resample&#34;) for k in self.dict_image}
        elif self.resample_spacing:
            step = {k: &#34;resample&#34; for k in self.dict_image}
            folder_path = {k: os.path.join(self.output_folder, &#34;resample&#34;) for k in self.dict_image}
        elif self.n4_correction:
            step = {k: &#34;n4&#34; if k in self.n4_correction else &#34;&#34; for k in self.dict_image}
            folder_path = {k: os.path.join(self.output_folder,
                                           &#34;n4_correction&#34;) if k in self.n4_correction else os.path.dirname(v) for
                           k, v in self.dict_image.items()}
        step_dict = {k: os.path.join(folder_path[k],
                                     self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                step=step[k]) +
                                     split_filename(v)[2]) for k, v in self.dict_image.items()} if \
            (self.resample_spacing or self.n4_correction) else copy.deepcopy(self.dict_image)
        reference_dict = {list(self.reference.keys())[0]: step_dict[list(self.reference.keys())[0]]} if \
            list(self.reference.values())[0] in self.dict_image.values() else copy.deepcopy(self.reference)
        self._run_coregistration(img_dict=step_dict, reference=reference_dict)

    if self.do_ss:
        step_dict = {k: os.path.join(self.output_folder, &#34;coregistration&#34;,
                                     self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                step=&#34;register&#34;) +
                                     split_filename(v)[2]) for k, v in step_dict.items()}
        reference_dict = {
            k: os.path.join(self.output_folder, &#34;coregistration&#34;,
                            self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                       step=&#34;register&#34;) +
                            split_filename(v)[2]) for k, v in reference_dict.items()}

        self._run_skull_stripping(img_dict=step_dict, reference=reference_dict)

    if self.normalize_z_score:
        step_dict = {k: os.path.join(self.output_folder, &#34;skullstripping&#34;,
                                     self.check_output_filename(filename=split_filename(v)[1], modality=k,
                                                                step=&#34;ss&#34;) +
                                     split_filename(v)[2]) for k, v in step_dict.items()}
        self._run_normalize_z_score(img_dict=step_dict)

    # if step to remove
    remove_step = set(self.save_step).symmetric_difference(set(self.default_step))
    if remove_step:
        for step_to_remove in remove_step:
            shutil.rmtree(path=os.path.join(self.output_folder, step_to_remove), ignore_errors=True)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="cBrainMRIPrePro" href="index.html">cBrainMRIPrePro</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="cBrainMRIPrePro.pipe.DataPreprocessing" href="#cBrainMRIPrePro.pipe.DataPreprocessing">DataPreprocessing</a></code></h4>
<ul class="">
<li><code><a title="cBrainMRIPrePro.pipe.DataPreprocessing.apply_brain_mask" href="#cBrainMRIPrePro.pipe.DataPreprocessing.apply_brain_mask">apply_brain_mask</a></code></li>
<li><code><a title="cBrainMRIPrePro.pipe.DataPreprocessing.check_output_filename" href="#cBrainMRIPrePro.pipe.DataPreprocessing.check_output_filename">check_output_filename</a></code></li>
<li><code><a title="cBrainMRIPrePro.pipe.DataPreprocessing.run_pipeline" href="#cBrainMRIPrePro.pipe.DataPreprocessing.run_pipeline">run_pipeline</a></code></li>
<li><code><a title="cBrainMRIPrePro.pipe.DataPreprocessing.save_image" href="#cBrainMRIPrePro.pipe.DataPreprocessing.save_image">save_image</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>